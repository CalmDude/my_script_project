{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439d8255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup and Parse Stock List\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import pandas as pd\n",
    "from script import parse_stocks_file\n",
    "\n",
    "ROOT = Path.cwd()\n",
    "stocks_file = ROOT / 'stocks.txt'\n",
    "\n",
    "# Parse stocks.txt to get individual tickers and baskets\n",
    "individual_tickers, baskets = parse_stocks_file(stocks_file)\n",
    "\n",
    "print(f\"Individual tickers: {individual_tickers}\")\n",
    "print(f\"\\nBaskets: {baskets}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9032f6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Run Batch Analysis\n",
    "from script import analyze_ticker, analyze_basket\n",
    "\n",
    "def run_batch(individual_tickers, baskets, concurrency=6, daily_bars=60, weekly_bars=52):\n",
    "    \"\"\"Run analysis on all individual tickers and baskets\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Analyze individual tickers in parallel\n",
    "    with ThreadPoolExecutor(max_workers=concurrency) as ex:\n",
    "        futures = {ex.submit(analyze_ticker, t, daily_bars, weekly_bars): t for t in individual_tickers}\n",
    "        for fut in as_completed(futures):\n",
    "            results.append(fut.result())\n",
    "    \n",
    "    # Analyze baskets (market cap weighted aggregations)\n",
    "    for basket_name, constituents in baskets.items():\n",
    "        basket_result = analyze_basket(basket_name, constituents, daily_bars, weekly_bars)\n",
    "        results.append(basket_result)\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Run the analysis\n",
    "df = run_batch(individual_tickers, baskets)\n",
    "df = df.round(2)\n",
    "\n",
    "# Print Summary Stats\n",
    "print(f\"\\nAnalysis complete: {len(df)} rows ({len(individual_tickers)} tickers + {len(baskets)} baskets)\")\n",
    "print(\"FULL HOLD + ADD tickers:\", ', '.join(df[df['signal'] == 'FULL HOLD + ADD']['ticker']))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89bd561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Print Buy Summary\n",
    "def print_buy_summary(df, cash_available=118305):\n",
    "    print(\"\\n### Larsson Portfolio Buy Summary ‚Äì Next Trading Day\\n\")\n",
    "    print(\"**Rule-Based Only** ‚Äî Conservative phased entry rules locked in:\")\n",
    "    print(\"- No immediate starters in Bullish zones (wait for better prices).\")\n",
    "    print(\"- Primary adds only on real weakness to predefined green supports.\\n\")\n",
    "    \n",
    "    print(f\"**Cash Available**: ~${cash_available:,.0f} (~59% dry powder)\\n\")\n",
    "    \n",
    "    # Load target allocations from targets.csv\n",
    "    targets_file = ROOT / 'targets.csv'\n",
    "    if targets_file.exists():\n",
    "        targets_df = pd.read_csv(targets_file)\n",
    "        target_dict = dict(zip(targets_df['ticker'], targets_df['target_pct']))\n",
    "        value_dict = dict(zip(targets_df['ticker'], targets_df['target_value']))\n",
    "    else:\n",
    "        target_dict = {}\n",
    "        value_dict = {}\n",
    "        print(\"‚ö†Ô∏è  targets.csv not found - using N/A for target percentages\\n\")\n",
    "    \n",
    "    # Use exact match instead of contains\n",
    "    eligible = df[df['signal'] == \"FULL HOLD + ADD\"]\n",
    "    if eligible.empty:\n",
    "        print(\"No FULL HOLD + ADD names ‚Äî no buys recommended.\")\n",
    "        return\n",
    "    \n",
    "    def get_primary_zone(row):\n",
    "        \"\"\"Hybrid conservative primary add zone: Lower Value Area + Key Long-Term SMAs\"\"\"\n",
    "        val = row['daily_val']\n",
    "        poc = row['daily_poc']\n",
    "        d100 = row['d100']\n",
    "        d200 = row['d200']\n",
    "        \n",
    "        # Handle NaN/missing\n",
    "        if pd.isna(val) or pd.isna(poc):\n",
    "            return f\"Near Key SMAs (D100 ${int(d100)} / D200 ${int(d200)})\"\n",
    "        \n",
    "        lower_va = f\"Lower Value Area (${int(val)}‚Äì${int(poc)})\"\n",
    "        sma_part = f\"or Key Long-Term SMA (D100 ${int(d100)} / D200 ${int(d200)})\"\n",
    "        return f\"{lower_va} {sma_part}\"\n",
    "    \n",
    "    print(\"| Ticker | Target % | Current Price (Close) | Confluence | Buy Recommendation | Primary Add (40‚Äì50% of target) | Primary Add Zone (Conservative) | Approx Shares at Zone |\")\n",
    "    print(\"|--------|----------|-----------------------|------------|------------------------------|--------------------------------|---------------------------------|-----------------------|\")\n",
    "    \n",
    "    for _, row in eligible.iterrows():\n",
    "        ticker = row['ticker']\n",
    "        price = row['current_price']\n",
    "        confluence = row['confluence']\n",
    "        rec = row['recommendation']\n",
    "        \n",
    "        # Get target % and value from config file\n",
    "        target_pct = target_dict.get(ticker, 'N/A')\n",
    "        target_val = value_dict.get(ticker, 4001)\n",
    "        \n",
    "        if target_pct != 'N/A':\n",
    "            target_pct_str = f\"{target_pct}%\"\n",
    "        else:\n",
    "            target_pct_str = 'N/A'\n",
    "        \n",
    "        # Calculate primary add amounts (40-50% of target)\n",
    "        primary_low = target_val * 0.4\n",
    "        primary_high = target_val * 0.5\n",
    "        \n",
    "        # Get primary zone\n",
    "        zone = get_primary_zone(row)\n",
    "        \n",
    "        # Share estimate using approximate zone midpoint (or current price fallback)\n",
    "        zone_mid_est = price * 0.9  # rough 10% dip estimate for conservatism\n",
    "        shares_low = int(primary_low / zone_mid_est)\n",
    "        shares_high = int(primary_high / zone_mid_est)\n",
    "        shares_str = f\"{shares_low}‚Äì{shares_high} shares\"\n",
    "        \n",
    "        print(f\"| **{ticker}** | {target_pct_str} | ${price:.2f} | **{confluence}** | {rec} | ~${primary_low:,.0f}‚Äì${primary_high:,.0f} | {zone} | {shares_str} |\")\n",
    "    \n",
    "    print(\"\\n**No Buy Action**\")\n",
    "    print(\"- All other names: Not FULL HOLD + ADD or confluence insufficient.\\n\")\n",
    "    print(\"**Execution Plan**\")\n",
    "    print(\"- No limits to place / Wait for weakness to primary zones / etc.\")\n",
    "\n",
    "print_buy_summary(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb2c436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Export Results\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "# Add timestamp to avoid overwriting\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "output_file = ROOT / f'batch_results_{timestamp}.csv'\n",
    "\n",
    "# Save to workspace\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"‚úÖ Results exported to: {output_file}\")\n",
    "\n",
    "# Copy to Downloads folder\n",
    "downloads_path = Path.home() / 'Downloads' / f'batch_results_{timestamp}.csv'\n",
    "try:\n",
    "    shutil.copy(output_file, downloads_path)\n",
    "    print(f\"‚úÖ File also copied to: {downloads_path}\")\n",
    "except PermissionError:\n",
    "    print(f\"‚ö†Ô∏è  Could not copy to Downloads - file may be open in another program\")\n",
    "    print(f\"   Close the file and try again, or use: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70358310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Cleanup Old Results\n",
    "from pathlib import Path\n",
    "\n",
    "def cleanup_old_results(keep_latest=1):\n",
    "    \"\"\"Keep only the most recent batch result file\"\"\"\n",
    "    batch_files = sorted(\n",
    "        ROOT.glob('batch_results_*.csv'),\n",
    "        key=lambda p: p.stat().st_mtime,\n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    for old_file in batch_files[keep_latest:]:\n",
    "        print(f\"üóëÔ∏è  Deleting: {old_file.name}\")\n",
    "        old_file.unlink()\n",
    "    \n",
    "    print(f\"‚úÖ Kept {min(len(batch_files), keep_latest)} most recent file(s)\")\n",
    "\n",
    "# Auto-cleanup after each run:\n",
    "cleanup_old_results(keep_latest=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
