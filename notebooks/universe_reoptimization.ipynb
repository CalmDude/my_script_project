{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "250fedba",
   "metadata": {},
   "source": [
    "# GHB Strategy - Universe Re-Optimization\n",
    "\n",
    "## üìã Purpose\n",
    "This notebook automates the annual universe refresh process:\n",
    "1. ‚úÖ Screen full S&P 500 for qualified stocks\n",
    "2. ‚úÖ Identify top 25 by CAGR\n",
    "3. ‚úÖ Compare to current universe\n",
    "4. ‚úÖ Recommend adds/drops\n",
    "5. ‚úÖ Analyze sector diversification\n",
    "6. ‚úÖ Generate updated universe list\n",
    "\n",
    "## ‚è±Ô∏è Runtime\n",
    "**Expected:** 10-15 minutes (downloads 5 years of data for 500 stocks)\n",
    "\n",
    "## üìÖ When to Run\n",
    "- **Required:** Annually (January each year)\n",
    "- **Optional:** When weekly scanner flags CRITICAL alert\n",
    "- **Emergency:** If >30% of universe in N2 for 2+ weeks\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0c915a",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9980d86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Add backtest directory to path\n",
    "sys.path.insert(0, str(Path('../backtest').resolve()))\n",
    "\n",
    "print(\"‚úÖ Libraries imported\")\n",
    "print(f\"üìÖ Re-optimization Date: {datetime.now().strftime('%Y-%m-%d %H:%M')}\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc835281",
   "metadata": {},
   "source": [
    "## Step 2: Load Current Universe\n",
    "\n",
    "Load your existing 25-stock universe to compare against new screening results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa5229d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load current universe from portfolio file\n",
    "portfolio_file = Path(\"../data/ghb_optimized_portfolio.txt\")\n",
    "\n",
    "current_universe = []\n",
    "if portfolio_file.exists():\n",
    "    with open(portfolio_file, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            # Skip comments and empty lines\n",
    "            if line and not line.startswith('#'):\n",
    "                current_universe.append(line)\n",
    "    \n",
    "    print(f\"üìä CURRENT UNIVERSE: {len(current_universe)} stocks\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Stocks: {', '.join(sorted(current_universe))}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Check last modification date\n",
    "    last_modified = datetime.fromtimestamp(portfolio_file.stat().st_mtime)\n",
    "    days_since = (datetime.now() - last_modified).days\n",
    "    print(f\"\\n‚è∞ Last Updated: {last_modified.strftime('%Y-%m-%d')} ({days_since} days ago)\")\n",
    "    \n",
    "    if days_since > 365:\n",
    "        print(\"üî¥ CRITICAL: Universe is over 1 year old - re-optimization overdue!\")\n",
    "    elif days_since > 180:\n",
    "        print(\"üü° WARNING: Universe is over 6 months old - consider updating\")\n",
    "    else:\n",
    "        print(\"‚úÖ Universe is relatively fresh\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No current universe file found - will create new one\")\n",
    "    current_universe = []\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc5fe87",
   "metadata": {},
   "source": [
    "## Step 3: Run S&P 500 Screening\n",
    "\n",
    "**This will take 10-15 minutes** as it downloads and analyzes 5 years of data for ~500 stocks.\n",
    "\n",
    "The screening applies GHB volatility criteria:\n",
    "- Standard Deviation ‚â• 30% OR\n",
    "- Max Win ‚â• 150% OR\n",
    "- Avg Win ‚â• 40%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecb04a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîÑ Running S&P 500 screening...\")\n",
    "print(\"‚è±Ô∏è Expected time: 10-15 minutes\")\n",
    "print(\"üì• Downloading 5 years of price data for ~500 stocks...\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Run screen_stocks.py\n",
    "result = subprocess.run(\n",
    "    ['python', '../backtest/screen_stocks.py', '--universe', 'sp500', '--refresh-data'],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "# Print output\n",
    "print(result.stdout)\n",
    "if result.stderr:\n",
    "    print(\"Warnings/Errors:\")\n",
    "    print(result.stderr)\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"\\n‚úÖ Screening completed successfully!\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå Screening failed with exit code {result.returncode}\")\n",
    "    print(\"Check the output above for errors.\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e21354",
   "metadata": {},
   "source": [
    "## Step 4: Load & Analyze Screening Results\n",
    "\n",
    "Load the CSV results and identify the top 25 stocks by CAGR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd25bfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most recent screening results\n",
    "results_dir = Path(\"../backtest/results\")\n",
    "screening_files = list(results_dir.glob(\"stock_screening_*.csv\"))\n",
    "\n",
    "if not screening_files:\n",
    "    print(\"‚ùå No screening results found!\")\n",
    "    print(\"Make sure the screening completed successfully in Step 3.\")\n",
    "else:\n",
    "    # Get most recent file\n",
    "    latest_file = max(screening_files, key=lambda p: p.stat().st_mtime)\n",
    "    print(f\"üìÑ Loading: {latest_file.name}\\n\")\n",
    "    \n",
    "    # Load results\n",
    "    df_screening = pd.read_csv(latest_file)\n",
    "    \n",
    "    # Separate qualified and non-qualified\n",
    "    df_qualified = df_screening[df_screening['Qualified'] == True].copy()\n",
    "    df_nonqualified = df_screening[df_screening['Qualified'] == False].copy()\n",
    "    \n",
    "    # Sort by CAGR\n",
    "    df_qualified = df_qualified.sort_values('CAGR', ascending=False)\n",
    "    \n",
    "    # Get top 25\n",
    "    df_top25 = df_qualified.head(25)\n",
    "    new_universe = df_top25['Ticker'].tolist()\n",
    "    \n",
    "    print(\"üìä SCREENING RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Total Stocks Tested: {len(df_screening)}\")\n",
    "    print(f\"Qualified: {len(df_qualified)} ({len(df_qualified)/len(df_screening)*100:.1f}%)\")\n",
    "    print(f\"Non-Qualified: {len(df_nonqualified)} ({len(df_nonqualified)/len(df_screening)*100:.1f}%)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if len(df_qualified) < 25:\n",
    "        print(f\"\\n‚ö†Ô∏è WARNING: Only {len(df_qualified)} stocks qualified (need 25)\")\n",
    "        print(\"Consider:\")\n",
    "        print(\"  - Lowering volatility thresholds\")\n",
    "        print(\"  - Expanding to Russell 1000\")\n",
    "        print(\"  - Checking if market conditions are unusual\")\n",
    "    \n",
    "    print(f\"\\nüìà TOP 25 STOCKS BY CAGR:\")\n",
    "    print(\"=\"*80)\n",
    "    print(df_top25[['Ticker', 'CAGR', 'Total_Return_%', 'Win_Rate_%', 'Avg_Win_%', 'Max_DD_%']].to_string(index=False))\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba92024d",
   "metadata": {},
   "source": [
    "## Step 5: Compare New vs Current Universe\n",
    "\n",
    "Analyze which stocks to keep, add, or remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e33e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(current_universe) > 0 and 'new_universe' in locals():\n",
    "    # Convert to sets for comparison\n",
    "    current_set = set(current_universe)\n",
    "    new_set = set(new_universe)\n",
    "    \n",
    "    # Calculate overlaps\n",
    "    keep_stocks = current_set & new_set  # Intersection\n",
    "    add_stocks = new_set - current_set    # In new but not current\n",
    "    drop_stocks = current_set - new_set   # In current but not new\n",
    "    \n",
    "    print(\"\\nüîÑ UNIVERSE COMPARISON\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Current Universe: {len(current_universe)} stocks\")\n",
    "    print(f\"New Top 25: {len(new_universe)} stocks\")\n",
    "    print(f\"Overlap: {len(keep_stocks)} stocks ({len(keep_stocks)/25*100:.1f}%)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Stocks to KEEP\n",
    "    print(f\"\\n‚úÖ KEEP ({len(keep_stocks)} stocks):\")\n",
    "    print(\"   These stocks are in both current and new top 25\")\n",
    "    if keep_stocks:\n",
    "        keep_list = sorted(list(keep_stocks))\n",
    "        for i in range(0, len(keep_list), 10):\n",
    "            print(f\"   {', '.join(keep_list[i:i+10])}\")\n",
    "    else:\n",
    "        print(\"   (None - complete universe refresh)\")\n",
    "    \n",
    "    # Stocks to ADD\n",
    "    print(f\"\\n‚ûï ADD ({len(add_stocks)} stocks):\")\n",
    "    print(\"   New winners that should be added to universe\")\n",
    "    if add_stocks:\n",
    "        # Show details for stocks to add\n",
    "        df_add = df_top25[df_top25['Ticker'].isin(add_stocks)][['Ticker', 'CAGR', 'Total_Return_%', 'Win_Rate_%']]\n",
    "        print(df_add.to_string(index=False))\n",
    "    else:\n",
    "        print(\"   (None - current universe is optimal)\")\n",
    "    \n",
    "    # Stocks to DROP\n",
    "    print(f\"\\n‚ûñ DROP ({len(drop_stocks)} stocks):\")\n",
    "    print(\"   Current stocks that didn't make new top 25\")\n",
    "    if drop_stocks:\n",
    "        drop_list = sorted(list(drop_stocks))\n",
    "        # Check if they still qualified\n",
    "        for ticker in drop_list:\n",
    "            if ticker in df_qualified['Ticker'].values:\n",
    "                rank = df_qualified[df_qualified['Ticker'] == ticker].index[0] + 1\n",
    "                cagr = df_qualified[df_qualified['Ticker'] == ticker]['CAGR'].values[0]\n",
    "                print(f\"   {ticker}: Still qualified but ranked #{rank} (CAGR: {cagr:.2f}%)\")\n",
    "            elif ticker in df_nonqualified['Ticker'].values:\n",
    "                print(f\"   {ticker}: ‚ùå NO LONGER QUALIFIES (failed volatility criteria)\")\n",
    "            else:\n",
    "                print(f\"   {ticker}: ‚ö†Ô∏è Not found in screening results\")\n",
    "    else:\n",
    "        print(\"   (None - all current stocks still top 25)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    \n",
    "    # Recommendation\n",
    "    overlap_pct = len(keep_stocks) / 25 * 100\n",
    "    \n",
    "    print(\"\\nüí° RECOMMENDATION:\")\n",
    "    if overlap_pct >= 80:\n",
    "        print(\"   ‚úÖ MINOR UPDATE: High overlap (>80%)\")\n",
    "        print(f\"   ‚Üí Keep {len(keep_stocks)} stocks, swap out {len(drop_stocks)} underperformers\")\n",
    "        print(\"   ‚Üí Low disruption to current portfolio\")\n",
    "    elif overlap_pct >= 50:\n",
    "        print(\"   üü° MODERATE UPDATE: Medium overlap (50-80%)\")\n",
    "        print(f\"   ‚Üí Keep {len(keep_stocks)} stocks, replace {len(drop_stocks)} with new winners\")\n",
    "        print(\"   ‚Üí Gradual transition recommended (4-8 weeks)\")\n",
    "    else:\n",
    "        print(\"   üî¥ MAJOR REFRESH: Low overlap (<50%)\")\n",
    "        print(f\"   ‚Üí Major universe shift: {len(add_stocks)} new stocks incoming\")\n",
    "        print(\"   ‚Üí Consider full portfolio reset or extended transition\")\n",
    "    \n",
    "elif 'new_universe' in locals():\n",
    "    print(\"\\nüìä NEW UNIVERSE (no comparison)\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Creating new universe with {len(new_universe)} stocks\")\n",
    "    print(f\"Stocks: {', '.join(sorted(new_universe))}\")\n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No screening results available for comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f79a08f",
   "metadata": {},
   "source": [
    "## Step 6: Sector Diversification Analysis\n",
    "\n",
    "Analyze sector concentration in new universe vs current."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231a7fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'new_universe' in locals():\n",
    "    # Manually define sectors for key stocks (simplified)\n",
    "    # In production, you'd fetch from yfinance or external API\n",
    "    sector_map = {\n",
    "        # Tech\n",
    "        'NVDA': 'Technology', 'SMCI': 'Technology', 'AVGO': 'Technology', 'GOOGL': 'Technology',\n",
    "        'GOOG': 'Technology', 'NFLX': 'Technology', 'ANET': 'Technology', 'ORCL': 'Technology',\n",
    "        'MU': 'Technology', 'APH': 'Technology', 'MSFT': 'Technology', 'META': 'Technology',\n",
    "        'AMD': 'Technology', 'AMAT': 'Technology', 'MRVL': 'Technology', 'FTNT': 'Technology',\n",
    "        'PANW': 'Technology', 'PLTR': 'Technology',\n",
    "        # Energy\n",
    "        'TRGP': 'Energy', 'MPC': 'Energy', 'DVN': 'Energy', 'WMB': 'Energy', 'FANG': 'Energy',\n",
    "        # Industrial\n",
    "        'GE': 'Industrial', 'AXON': 'Industrial', 'PWR': 'Industrial', 'CTAS': 'Industrial',\n",
    "        # Healthcare\n",
    "        'LLY': 'Healthcare', 'MCK': 'Healthcare', 'CAH': 'Healthcare', 'MRNA': 'Healthcare',\n",
    "        'VRTX': 'Healthcare',\n",
    "        # Utilities\n",
    "        'CEG': 'Utilities', 'VST': 'Utilities',\n",
    "        # Consumer\n",
    "        'DECK': 'Consumer', 'STX': 'Consumer', 'COST': 'Consumer', 'AMZN': 'Consumer',\n",
    "        'TSLA': 'Consumer', 'BKNG': 'Consumer', 'ROST': 'Consumer',\n",
    "        # Financial\n",
    "        'JPM': 'Financial',\n",
    "    }\n",
    "    \n",
    "    # Assign sectors to new universe\n",
    "    new_sectors = {}\n",
    "    for ticker in new_universe:\n",
    "        sector = sector_map.get(ticker, 'Other')\n",
    "        new_sectors[sector] = new_sectors.get(sector, 0) + 1\n",
    "    \n",
    "    print(\"\\nüìä NEW UNIVERSE - SECTOR BREAKDOWN\")\n",
    "    print(\"=\"*80)\n",
    "    for sector in sorted(new_sectors.keys(), key=lambda x: new_sectors[x], reverse=True):\n",
    "        count = new_sectors[sector]\n",
    "        pct = count / 25 * 100\n",
    "        print(f\"{sector:15s}: {count:2d} stocks ({pct:5.1f}%)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Check for concentration risk\n",
    "    max_sector_pct = max(new_sectors.values()) / 25 * 100\n",
    "    if max_sector_pct > 50:\n",
    "        print(\"\\nüî¥ WARNING: High sector concentration (>50% in one sector)\")\n",
    "        print(\"   ‚Üí Consider diversifying to reduce sector risk\")\n",
    "    elif max_sector_pct > 40:\n",
    "        print(\"\\nüü° WATCH: Moderate sector concentration (40-50%)\")\n",
    "        print(\"   ‚Üí Monitor sector trends closely\")\n",
    "    else:\n",
    "        print(\"\\n‚úÖ HEALTHY: Good sector diversification\")\n",
    "    \n",
    "    # Compare to current if available\n",
    "    if len(current_universe) > 0:\n",
    "        current_sectors = {}\n",
    "        for ticker in current_universe:\n",
    "            sector = sector_map.get(ticker, 'Other')\n",
    "            current_sectors[sector] = current_sectors.get(sector, 0) + 1\n",
    "        \n",
    "        print(\"\\nüìä CURRENT UNIVERSE - SECTOR BREAKDOWN (for comparison)\")\n",
    "        print(\"=\"*80)\n",
    "        for sector in sorted(current_sectors.keys(), key=lambda x: current_sectors[x], reverse=True):\n",
    "            count = current_sectors[sector]\n",
    "            pct = count / len(current_universe) * 100\n",
    "            print(f\"{sector:15s}: {count:2d} stocks ({pct:5.1f}%)\")\n",
    "        print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59956c8a",
   "metadata": {},
   "source": [
    "## Step 7: Generate Updated Universe Files\n",
    "\n",
    "Create the updated stock list for both the notebook and text file.\n",
    "\n",
    "**‚ö†Ô∏è This does NOT automatically update your files - you must manually copy/paste.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4e6df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'new_universe' in locals():\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìù UPDATED UNIVERSE CODE\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\n1Ô∏è‚É£ FOR NOTEBOOK (ghb_portfolio_scanner.ipynb):\")\n",
    "    print(\"   Copy and paste this into the GHB_UNIVERSE cell:\\n\")\n",
    "    print(\"```python\")\n",
    "    print(\"# GHB Strategy S&P 500 Optimized Portfolio - 25 Stocks\")\n",
    "    print(f\"# Re-optimized: {datetime.now().strftime('%Y-%m-%d')}\")\n",
    "    print(\"GHB_UNIVERSE = [\")\n",
    "    \n",
    "    # Format in rows of 4-5 stocks\n",
    "    sorted_universe = sorted(new_universe)\n",
    "    for i in range(0, len(sorted_universe), 5):\n",
    "        batch = sorted_universe[i:i+5]\n",
    "        line = ', '.join([f\"'{ticker}'\" for ticker in batch])\n",
    "        if i + 5 < len(sorted_universe):\n",
    "            line += ','\n",
    "        print(f\"    {line}\")\n",
    "    \n",
    "    print(\"]\")\n",
    "    print(\"```\\n\")\n",
    "    \n",
    "    print(\"2Ô∏è‚É£ FOR TEXT FILE (data/ghb_optimized_portfolio.txt):\")\n",
    "    print(\"   Replace file contents with this:\\n\")\n",
    "    print(\"```\")\n",
    "    print(\"# GHB Strategy Optimized Portfolio - S&P 500 Optimized Universe (25 stocks)\")\n",
    "    print(f\"# Re-optimized: {datetime.now().strftime('%Y-%m-%d')}\")\n",
    "    print(\"# Updated: [Your next update date - typically 1 year from now]\")\n",
    "    print(\"#\")\n",
    "    print(\"# Stocks (Top 25 S&P 500 by CAGR - sorted alphabetically):\")\n",
    "    for ticker in sorted_universe:\n",
    "        print(ticker)\n",
    "    print(\"```\\n\")\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"üìã NEXT STEPS:\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"1. Review the recommendations above\")\n",
    "    print(\"2. Decide: Full refresh, partial update, or keep current?\")\n",
    "    print(\"3. If updating:\")\n",
    "    print(\"   a. Copy notebook code to ghb_portfolio_scanner.ipynb\")\n",
    "    print(\"   b. Copy text to data/ghb_optimized_portfolio.txt\")\n",
    "    print(\"   c. Run backtest to validate (optional)\")\n",
    "    print(\"4. Plan portfolio transition (immediate/gradual/hybrid)\")\n",
    "    print(\"5. Execute trades over 2-8 weeks\")\n",
    "    print(\"\\nüìÑ See: docs/RE-OPTIMIZATION_GUIDE.md for detailed instructions\")\n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No new universe available to generate code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38177e0",
   "metadata": {},
   "source": [
    "## Step 8: Save Analysis Report\n",
    "\n",
    "Save a detailed report of this re-optimization for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbc30b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'new_universe' in locals() and len(current_universe) > 0:\n",
    "    # Create report\n",
    "    report_dir = Path(\"../backtest/results\")\n",
    "    report_file = report_dir / f\"reoptimization_report_{datetime.now().strftime('%Y%m%d_%H%M')}.txt\"\n",
    "    \n",
    "    with open(report_file, 'w') as f:\n",
    "        f.write(\"GHB STRATEGY - UNIVERSE RE-OPTIMIZATION REPORT\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M')}\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(\"SUMMARY\\n\")\n",
    "        f.write(\"-\" * 80 + \"\\n\")\n",
    "        f.write(f\"Current Universe: {len(current_universe)} stocks\\n\")\n",
    "        f.write(f\"New Top 25: {len(new_universe)} stocks\\n\")\n",
    "        f.write(f\"Overlap: {len(keep_stocks)} stocks ({len(keep_stocks)/25*100:.1f}%)\\n\")\n",
    "        f.write(f\"To Add: {len(add_stocks)} stocks\\n\")\n",
    "        f.write(f\"To Drop: {len(drop_stocks)} stocks\\n\\n\")\n",
    "        \n",
    "        f.write(\"STOCKS TO KEEP\\n\")\n",
    "        f.write(\"-\" * 80 + \"\\n\")\n",
    "        for ticker in sorted(keep_stocks):\n",
    "            f.write(f\"  {ticker}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "        f.write(\"STOCKS TO ADD\\n\")\n",
    "        f.write(\"-\" * 80 + \"\\n\")\n",
    "        for ticker in sorted(add_stocks):\n",
    "            row = df_top25[df_top25['Ticker'] == ticker].iloc[0]\n",
    "            f.write(f\"  {ticker}: CAGR {row['CAGR']:.2f}%, Win Rate {row['Win_Rate_%']:.1f}%\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "        f.write(\"STOCKS TO DROP\\n\")\n",
    "        f.write(\"-\" * 80 + \"\\n\")\n",
    "        for ticker in sorted(drop_stocks):\n",
    "            if ticker in df_qualified['Ticker'].values:\n",
    "                rank = df_qualified[df_qualified['Ticker'] == ticker].index[0] + 1\n",
    "                cagr = df_qualified[df_qualified['Ticker'] == ticker]['CAGR'].values[0]\n",
    "                f.write(f\"  {ticker}: Still qualified but ranked #{rank} (CAGR: {cagr:.2f}%)\\n\")\n",
    "            else:\n",
    "                f.write(f\"  {ticker}: No longer qualifies\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "        f.write(\"NEW UNIVERSE (alphabetical)\\n\")\n",
    "        f.write(\"-\" * 80 + \"\\n\")\n",
    "        for ticker in sorted(new_universe):\n",
    "            f.write(f\"  {ticker}\\n\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Report saved: {report_file.name}\")\n",
    "    print(f\"üìÅ Location: {report_file.parent.absolute()}\")\n",
    "else:\n",
    "    print(\"\\n‚è≠Ô∏è Skipping report (no comparison available)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411cedae",
   "metadata": {},
   "source": [
    "## üìä Summary\n",
    "\n",
    "### What This Notebook Did:\n",
    "1. ‚úÖ Loaded your current 25-stock universe\n",
    "2. ‚úÖ Screened full S&P 500 (~500 stocks)\n",
    "3. ‚úÖ Identified qualified stocks and ranked by CAGR\n",
    "4. ‚úÖ Compared new top 25 vs current universe\n",
    "5. ‚úÖ Analyzed which stocks to keep/add/drop\n",
    "6. ‚úÖ Checked sector diversification\n",
    "7. ‚úÖ Generated updated universe code\n",
    "8. ‚úÖ Saved detailed report\n",
    "\n",
    "### Your Decision:\n",
    "Based on the analysis above, decide:\n",
    "- **Keep current universe?** (if overlap >80% and performance good)\n",
    "- **Partial update?** (swap out worst performers)\n",
    "- **Full refresh?** (replace with new top 25)\n",
    "\n",
    "### If Updating:\n",
    "1. Copy the generated code from Step 7\n",
    "2. Update `ghb_portfolio_scanner.ipynb` (GHB_UNIVERSE cell)\n",
    "3. Update `data/ghb_optimized_portfolio.txt`\n",
    "4. Optional: Run backtest to validate performance\n",
    "5. Plan portfolio transition strategy\n",
    "\n",
    "### Documentation:\n",
    "üìÑ Full guide: `docs/RE-OPTIMIZATION_GUIDE.md`\n",
    "\n",
    "---\n",
    "\n",
    "**Next re-optimization:** January 2027 (1 year from now)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
